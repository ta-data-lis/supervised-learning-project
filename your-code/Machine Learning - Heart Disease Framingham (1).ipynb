{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Heart Disease Prediction\n### Will a patient have a CVD - 10 year risk?\n\n### Table of contents\n1. [Introduction](#introduction)\n2. [Exploratory Data Analysis](#paragraph1)\n3. [Feature Scaling](#paragraph2)\n4. [Test - Train Split](#paragraph3)\n5. [Resampling](#paragraph4)\n6. [Modelling & Evaluation](#paragraph5)\n3. [Apply model](#paragraph6)\n\n## Introduction <a name=\"introduction\"></a>\n\n**Problem:**\nThe World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk using logistic regression Data Preparation\n\n**Source:**\nThe dataset is publically available on the Kaggle website, and it is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).The dataset provides the patients’ information. It includes over 4,000 records and 15 attributes. Variables Each attribute is a potential risk factor. There are both demographic, behavioral and medical risk factors.\n\n**Attributes:**\n\nDemographic: \n* Sex: male or female(Nominal) \n* Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous) \n* Education: no further information provided\n\nBehavioral: \n* Current Smoker: whether or not the patient is a current smoker (Nominal) \n* Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.) \n\nMedical( history): \n* BP Meds: whether or not the patient was on blood pressure medication (Nominal) \n* Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal) \n* Prevalent Hyp: whether or not the patient was hypertensive (Nominal) \n* Diabetes: whether or not the patient had diabetes (Nominal) \n\nMedical(current): \n* Tot Chol: total cholesterol level (Continuous) \n* Sys BP: systolic blood pressure (Continuous) \n* Dia BP: diastolic blood pressure (Continuous) \n* BMI: Body Mass Index (Continuous) \n* Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.) \n* Glucose: glucose level (Continuous) \n\nPredict variable (desired target): \n* 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n%config InlineBackend.figure_format ='retina'\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis <a name=\"paragraph1\"></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/framingham-heart-study-dataset/framingham.csv')\ndf.head(20)\ndf.shape\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for dupicates\nduplicate_df = df[df.duplicated()]\nduplicate_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\ndf.isna().sum()\nnull = df[df.isna().any(axis=1)]\nnull","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distributions\n\nfig = plt.figure(figsize = (15,20))\n#fig = plt.grid(b=None)\nax = fig.gca()\n#plt.axis('off')\n\ndf.hist(ax = ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking which features are correlated with each other and with the outcome variable\ndf_corr = df.corr()\nsns.heatmap(df_corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Dropping education because a doctor would have to decide on which education level to put a patient and this could yield in very subjective biased outcomes. \nAlso dropping the column glucose due to missing data in this feature.\nSince these features are not correlated to the outcome variable we will not lose much information."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping education and glucose\ndf = df.drop(['education','glucose'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for more missing data \ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping rows with missing data\ndf = df.dropna()\ndf.isna().sum()\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify those features with the most importance for the outcome variable Heart Disease\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nX = df.iloc[:,0:15]  #independent columns\ny = df.iloc[:,-1]    #target column i.e price range\n#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(11,'Score'))  #print 10 best features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScores = featureScores.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScores_feat = featureScores [1:]\nsns.barplot(x='Specs', y='Score', data=featureScores_feat, palette = \"GnBu_d\")\n#sns.set(rc={'figure.figsize':(21,8)})\nplt.box(False)\nplt.title('Feature importance', fontsize=16)\nplt.xlabel('Features', fontsize=14)\nplt.ylabel('Importance', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScores = featureScores.sort_values(by='Score', ascending=False)\nfeatures_list = featureScores[\"Specs\"].tolist()[:-3]\nfeatures_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will only keep those features that have the strongest relationship with the output variable. These features are:\n- Systolic Blood Pressure\n- Diastolic Blood Pressure\n- Age\n- Gender\n- BMI\n- Cigarettes per Day\n- Cholesterin\n- Blood Pressure Medication\n- Diabetes\n- Hypertensive"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new dataframe with selected features\n\ndf = df[['sysBP','age','cigsPerDay','totChol', 'diaBP','prevalentHyp','diabetes','BPMeds','male','BMI','TenYearCHD']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking correlation again\ndf_corr = df.corr()\nsns.heatmap(df_corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for outliers\ndf.describe()\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Zooming into cholesterin outliers\n\nsns.boxplot(df.totChol)\n\n# Removing outliers\noutliers = df[(df['totChol'] > 500)] \noutliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping outliers\ndf = df.drop(df[df.totChol > 599].index)\nsns.boxplot(df.totChol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Feature Scaling <a name=\"paragraph2\"></a>\nSince we want to try out different models, and also these that use distance as a measure, we will scale our features."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0,1)) \n\n#assign scaler to column:\ndf_scaled = pd.DataFrame(scaler.fit_transform(df_clean), columns=df_clean.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaled.describe()\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test - Train Split <a name=\"paragraph3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clarify what is y and what is x label\ny = df_scaled['TenYearCHD']\nX = df_scaled.drop(['TenYearCHD'], axis = 1)\n\n# divide train test: 80 % - 20 %\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=29)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train)\nlen(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resampling imbalanced Dataset <a name=\"paragraph4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking balance of outcome variable\ntarget_count = df.TenYearCHD.value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n\nsns.countplot(df.TenYearCHD, palette=\"OrRd\")\nplt.box(False)\nplt.xlabel('Heart Disease No/Yes',fontsize=11)\nplt.ylabel('Patient Count',fontsize=11)\nplt.title('Count Outcome Heart Disease\\n')\nplt.savefig('Balance Heart Disease.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the proportion is 5.7:1 which is not well balanced.\nOne of the major issues when dealing with unbalanced datasets relates to the metrics used to evaluate a model. Using simpler metrics like accuracy_score can be misleading. In a dataset with highly unbalanced classes, if the classifier always \"predicts\" the most common class without performing any analysis of the features, it will still have a high accuracy rate, obviously illusory."},{"metadata":{},"cell_type":"markdown","source":"### UNDERSAMPLING METHOD"},{"metadata":{},"cell_type":"markdown","source":"Undersampling aims to decrease the number of instances from the overrepresented class in the data set. In our case, these techniques will decrease the number of fraudulent transactions in our data to 50:50. If you do not balance the number of instances, most classification algorithms will heavily focus on the majority class. As a result, it might seem like your algorithm is achieving superb results when, in reality, it is simply always predicting the majority class.\n\nThe easiest way to do so is to randomly select observations from the majority class and remove them from the data set until we achieve a balance between the majority and minority class.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Distribution before resampling: \",df_clean.TenYearCHD.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffled_df = df_scaled.sample(frac=1,random_state=4)\n\n# Put all the fraud class in a separate dataset.\nCHD_df = shuffled_df.loc[shuffled_df['TenYearCHD'] == 1]\n\n#Randomly select 492 observations from the non-fraud (majority class)\nnon_CHD_df = shuffled_df.loc[shuffled_df['TenYearCHD'] == 0].sample(n=611,random_state=42)\n\n# Concatenate both dataframes again\nnormalized_df = pd.concat([CHD_df, non_CHD_df])\n\n# check new class counts\nnormalized_df.TenYearCHD.value_counts()\n\n# plot new count\nsns.countplot(normalized_df.TenYearCHD, palette=\"OrRd\")\nplt.box(False)\nplt.xlabel('Heart Disease No/Yes',fontsize=11)\nplt.ylabel('Patient Count',fontsize=11)\nplt.title('Count Outcome Heart Disease after Resampling\\n')\n#plt.savefig('Balance Heart Disease.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling & Evaluation <a name=\"paragraph5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 1. Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"normalized_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# logistic regression again with the balanced dataset\ny_train = normalized_df['TenYearCHD']\nX_train = normalized_df.drop('TenYearCHD', axis=1)\n\nnormalized_df_reg = LogisticRegression().fit(X_train, y_train)\n\nnormalized_df_reg_pred = normalized_df_reg.predict(X_test)\n\n# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\nacc = accuracy_score(y_test, normalized_df_reg_pred)\nprint(f\"The accuracy score for LogReg is: {round(acc,3)*100}%\")\n\n# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\nf1 = f1_score(y_test, normalized_df_reg_pred)\nprint(f\"The f1 score for LogReg is: {round(f1,3)*100}%\")\n\n# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\nprecision = precision_score(y_test, normalized_df_reg_pred)\nprint(f\"The precision score for LogReg is: {round(precision,3)*100}%\")\n\n# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\nrecall = recall_score(y_test, normalized_df_reg_pred)\nprint(f\"The recall score for LogReg is: {round(recall,3)*100}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting confusion matrix LogReg\n\ncnf_matrix_log = confusion_matrix(y_test, normalized_df_reg_pred)\n\nsns.heatmap(pd.DataFrame(cnf_matrix_log), annot=True,cmap=\"Blues\" , fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix Logistic Regression\\n', y=1.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine\n\n#initialize model\nsvm = SVC()\n\n#fit model\nsvm.fit(X_train, y_train)\n\nnormalized_df_svm_pred = svm.predict(X_test)\n\n# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\nacc = accuracy_score(y_test, normalized_df_svm_pred)\nprint(f\"The accuracy score for SVM is: {round(acc,3)*100}%\")\n\n# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\nf1 = f1_score(y_test, normalized_df_svm_pred)\nprint(f\"The f1 score for SVM is: {round(f1,3)*100}%\")\n\n# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\nprecision = precision_score(y_test, normalized_df_svm_pred)\nprint(f\"The precision score for SVM is: {round(precision,3)*100}%\")\n\n# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\nrecall = recall_score(y_test, normalized_df_svm_pred)\nprint(f\"The recall score for SVM is: {round(recall,3)*100}%\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting confusion matrix SVM\n\ncnf_matrix_svm = confusion_matrix(y_test, normalized_df_svm_pred)\n\nsns.heatmap(pd.DataFrame(cnf_matrix_svm), annot=True,cmap=\"Reds\" , fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix SVM\\n', y=1.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\n\n#initialize model\ndtc_up = DecisionTreeClassifier()\n\n# fit model\ndtc_up.fit(X_train, y_train)\n\nnormalized_df_dtc_pred = dtc_up.predict(X_test)\n\n# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\nacc = accuracy_score(y_test, normalized_df_dtc_pred)\nprint(f\"The accuracy score for DTC is: {round(acc,3)*100}%\")\n\n# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\nf1 = f1_score(y_test, normalized_df_dtc_pred)\nprint(f\"The f1 score for DTC is: {round(f1,3)*100}%\")\n\n# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\nprecision = precision_score(y_test, normalized_df_dtc_pred)\nprint(f\"The precision score for DTC is: {round(precision,3)*100}%\")\n\n# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\nrecall = recall_score(y_test, normalized_df_dtc_pred)\nprint(f\"The recall score for DTC is: {round(recall,3)*100}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting confusion matrix Decision Tree\n\ncnf_matrix_dtc = confusion_matrix(y_test, normalized_df_dtc_pred)\n\nsns.heatmap(pd.DataFrame(cnf_matrix_dtc), annot=True,cmap=\"Reds\" , fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix Decision Tree\\n', y=1.1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN Model\n\n#initialize model\nknn = KNeighborsClassifier(n_neighbors = 2)\n\n#fit model\nknn.fit(X_train, y_train)\n\n# prediction = knn.predict(x_test)\nnormalized_df_knn_pred = knn.predict(X_test)\n\n\n# check accuracy: Accuracy: Overall, how often is the classifier correct? Accuracy = (True Pos + True Negative)/total\nacc = accuracy_score(y_test, normalized_df_knn_pred)\nprint(f\"The accuracy score for KNN is: {round(acc,3)*100}%\")\n\n# f1 score: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\nf1 = f1_score(y_test, normalized_df_knn_pred)\nprint(f\"The f1 score for KNN is: {round(f1,3)*100}%\")\n\n# Precision score: When it predicts yes, how often is it correct? Precision=True Positive/predicted yes\nprecision = precision_score(y_test, normalized_df_knn_pred)\nprint(f\"The precision score for KNN is: {round(precision,3)*100}%\")\n\n# recall score: True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes? True Positive Rate = True Positive/actual yes\nrecall = recall_score(y_test, normalized_df_knn_pred)\nprint(f\"The recall score for KNN is: {round(recall,3)*100}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check overfitting of the KNN model\n# accuracy test and train\nacc_test = knn.score(X_test, y_test)\nacc_test\nacc_train = knn.score(X_train, y_train)\nacc_train\n\n# Perform cross validation\n# Cross Validation is used to assess the predictive performance of the models and and to judge how they perform outside the sample to a new data set \n\ncv_results = cross_val_score(knn, X, y, cv=5) \n\nprint (\"Cross-validated scores:\", cv_results)\n\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (cv_results.mean(), cv_results.std() * 2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting confusion matrix KNN\n\ncnf_matrix_knn = confusion_matrix(y_test, normalized_df_knn_pred)\n\nax= plt.subplot()\nsns.heatmap(pd.DataFrame(cnf_matrix_knn), annot=True,cmap=\"Reds\" , fmt='g')\n\n#plt.tight_layout()\n#plt.title('Confusion matrix KNN\\n', y=1.1)\n\n# labels, title and ticks\nax.set_xlabel('Predicted ');ax.set_ylabel('True'); \n#ax.xaxis.set_ticklabels(['No Heart Disease', 'Heart Disease']); ax.yaxis.set_ticklabels(['Heart Disease', 'No Heart Disease'])\n#ax.xaxis.set_ticks_position(\"default\")\n#ax.yaxis.set_ticks_position('default')\n\n#rotation=45","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AU ROC CURVE\n# the AUC ROC Curve is a measure of performance based on plotting the true positive and false positive rate and calculating the area under that curve.\n# The closer the score to 1 the better the algorithm's ability to distinguish between the two outcome classes.\n\nfpr, tpr, _ = roc_curve(y_test, normalized_df_knn_pred)\nauc = roc_auc_score(y_test, normalized_df_knn_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.box(False)\nplt.title ('ROC CURVE KNN')\nplt.show()\n\nprint(f\"The score for the AUC ROC Curve is: {round(auc,3)*100}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apply the model <a name=\"paragraph6\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def start_questionnaire():\n    my_predictors = []\n    parameters=['sysBP', 'age', 'cigsPerDay', 'totChol', 'diaBP', 'prevalentHyp','diabetes', 'BPMeds', 'male', 'BMI']\n    \n    print('Input Patient Information:')\n    age = input(\"Patient's age: >>> \") \n    my_predictors.append(age)\n    male = input(\"Patient's gender. male=1, female=0: >>> \") \n    my_predictors.append(male)\n    cigsPerDay = input(\"Patient's smoked cigarettes per day: >>> \") \n    my_predictors.append(cigsPerDay)\n    BMI = input(\"Patient's BMI: >>> \") \n    my_predictors.append(BMI)\n    sysBP = input(\"Patient's systolic blood pressure: >>> \") \n    my_predictors.append(sysBP)\n    diaBP = input(\"Patient's diastolic blood pressure: >>> \")\n    my_predictors.append(diaBP)\n    totChol = input(\"Patient's cholesterin level: >>> \") \n    my_predictors.append(totChol)\n    prevalentHyp = input(\"Was Patient hypertensive? Yes=1, No=0 >>> \") \n    my_predictors.append(prevalentHyp)\n    diabetes = input(\"Did Patient have diabetes? Yes=1, No=0 >>> \") \n    my_predictors.append(diabetes)\n    BPMeds = input(\"Has Patient been on Blood Pressure Medication? Yes=1, No=0 >>> \")\n    \n    my_data = dict(zip(parameters, my_predictors))\n    my_df = pd.DataFrame(my_data, index=[0])\n    scaler = MinMaxScaler(feature_range=(0,1)) \n    #assign scaler to column:\n    my_df_scaled = pd.DataFrame(scaler.fit_transform(my_df), columns=my_df.columns)\n    my_y_pred = knn.predict(my_df)\n    print('\\n')\n    print('Result:')\n    if my_y_pred == 1:\n        print(\"The patient will develop a Heart Disease.\")\n    if my_y_pred == 0:\n        print(\"The patient will not develop a Heart Disease.\")\n        \n#start_questionnaire()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}